{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification with Deep Learning (CIFAR-10)"
      ],
      "metadata": {
        "id": "-jE3YLWGYvyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6jUbvdN-a-Z",
        "outputId": "5495fa8f-a873-4d2d-8816-0eb5bab115a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "HD5FEd6lYqv6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hU7_0SOM9xKT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class ResNet:\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\tshortcut = data\n",
        "\n",
        "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
        "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
        "\t\tact1 = Activation(\"relu\")(bn1)\n",
        "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
        "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
        "\t\tact2 = Activation(\"relu\")(bn2)\n",
        "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
        "\n",
        "\t\t# the third block of the ResNet module is another set of 1x1 CONVs\n",
        "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
        "\t\tact3 = Activation(\"relu\")(bn3)\n",
        "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
        "\t\t# the shortcut\n",
        "\t\tif red:\n",
        "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
        "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# add together the shortcut and the final CONV\n",
        "\t\tx = add([conv3, shortcut])\n",
        "\n",
        "\t\t# return the addition as the output of the ResNet module\n",
        "\t\treturn x\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, stages, filters,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# set the input and apply BN\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(inputs)\n",
        "\n",
        "\t\t# check if we are utilizing the CIFAR dataset\n",
        "\t\tif dataset == \"cifar\":\n",
        "\t\t\tx = Conv2D(filters[0], (3, 3), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\n",
        "\t\t# check to see if we are using the Tiny ImageNet dataset\n",
        "\t\telif dataset == \"tiny_imagenet\":\n",
        "\t\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
        "\t\t\tx = Conv2D(filters[0], (5, 5), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "\t\t\tx = Activation(\"relu\")(x)\n",
        "\t\t\tx = ZeroPadding2D((1, 1))(x)\n",
        "\t\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\t\t# loop over the number of stages\n",
        "\t\tfor i in range(0, len(stages)):\n",
        "\t\t\t# initialize the stride, then apply a residual module\n",
        "\t\t\t# used to reduce the spatial size of the input volume\n",
        "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
        "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride, chanDim, \n",
        "\t\t\t                           red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t\t# loop over the number of layers in the stage\n",
        "\t\t\tfor j in range(0, stages[i] - 1):\n",
        "\t\t\t\t# apply a ResNet module\n",
        "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1], (1, 1), \n",
        "\t\t\t\t                           chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t# apply BN => ACT => POOL\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = AveragePooling2D((8, 8))(x)\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t\t# create the model\n",
        "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
        "\t\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FLWz1bMN96BA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import os\n",
        "\n",
        "class EpochCheckpoint(Callback):\n",
        "\tdef __init__(self, outputPath, every=5, startAt=0):\n",
        "\t\tsuper(Callback, self).__init__()\n",
        "\n",
        "\t\tself.outputPath = outputPath\n",
        "\t\tself.every = every\n",
        "\t\tself.intEpoch = startAt\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif (self.intEpoch + 1) % self.every == 0:\n",
        "\t\t\tp = os.path.sep.join([self.outputPath, \"epoch_{}.hdf5\".format(self.intEpoch + 1)])\n",
        "\t\t\tself.model.save(p, overwrite=True)\n",
        "\n",
        "\t\t# increment the internal epoch counter\n",
        "\t\tself.intEpoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7LidmgEY-DDr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import BaseLogger\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "class TrainingMonitor(BaseLogger):\n",
        "\tdef __init__(self, figPath, jsonPath=None, startAt=0):\n",
        "\t\tsuper(TrainingMonitor, self).__init__()\n",
        "\t\tself.figPath = figPath\n",
        "\t\tself.jsonPath = jsonPath\n",
        "\t\tself.startAt = startAt\n",
        "\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.H = {}\n",
        "\n",
        "\t\tif self.jsonPath is not None:\n",
        "\t\t\tif os.path.exists(self.jsonPath):\n",
        "\t\t\t\tself.H = json.loads(open(self.jsonPath).read())\n",
        "\n",
        "\t\t\t\tif self.startAt > 0:\n",
        "\t\t\t\t\tfor k in self.H.keys():\n",
        "\t\t\t\t\t\tself.H[k] = self.H[k][:self.startAt]\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tfor (k, v) in logs.items():\n",
        "\t\t\tl = self.H.get(k, [])\n",
        "\t\t\tl.append(float(v))\n",
        "\t\t\tself.H[k] = l\n",
        "\n",
        "\t\tif self.jsonPath is not None:\n",
        "\t\t\tf = open(self.jsonPath, \"w\")\n",
        "\t\t\tf.write(json.dumps(self.H))\n",
        "\t\t\tf.close()\n",
        "\n",
        "\t\tif len(self.H[\"loss\"]) > 1:\n",
        "\t\t\tN = np.arange(0, len(self.H[\"loss\"]))\n",
        "\t\t\tplt.style.use(\"ggplot\")\n",
        "\t\t\tplt.figure()\n",
        "\t\t\tplt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
        "\t\t\tplt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
        "\t\t\tplt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\n",
        "\t\t\tplt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\n",
        "\t\t\tplt.title(\"Training Loss and Accuracy [Epoch {}]\".format(\n",
        "\t\t\t\tlen(self.H[\"loss\"])))\n",
        "\t\t\tplt.xlabel(\"Epoch #\")\n",
        "\t\t\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\t\t\tplt.legend()\n",
        "\n",
        "\t\t\t# save the figure\n",
        "\t\t\tplt.savefig(self.figPath)\n",
        "\t\t\tplt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xs0OJRQd-Tk6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import argparse\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vJ5DNRxq-w3H"
      },
      "outputs": [],
      "source": [
        "# set a high recursion limit so Theano doesn't complain\n",
        "sys.setrecursionlimit(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw9nR3VI-zgj",
        "outputId": "162ececb-489e-4848-b124-01eae67ed918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading CIFAR-10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load the training and testing data, converting the images from\n",
        "# integers to floats\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float\")\n",
        "testX = testX.astype(\"float\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3f20aFFx-_-s"
      },
      "outputs": [],
      "source": [
        "# apply mean subtraction to the data\n",
        "mean = np.mean(trainX, axis=0)\n",
        "trainX -= mean\n",
        "testX -= mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rXA4KV-W_Cx2"
      },
      "outputs": [],
      "source": [
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_iSS-kMd_EgB"
      },
      "outputs": [],
      "source": [
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, horizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSGLq90M_G4b",
        "outputId": "f93b8cfc-f7f0-43c4-e373-4c55b2482b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# if there is no specific model checkpoint supplied, then initialize\n",
        "# the network (ResNet-56) and compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=1e-1)\n",
        "\n",
        "model = ResNet.build(32, 32, 3, 10, (9, 9, 9), (64, 64, 128, 256), reg=0.0005)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nxYulIem_431"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"/content/drive/My Drive/data_science/output/checkpoints/\"\n",
        "myfigPath = \"/content/drive/My Drive/data_science/output/resnet56_cifar10.png\"\n",
        "myJsonPath = \"/content/drive/My Drive/data_science/output/resnet56_cifar10.json\"\n",
        "\n",
        "callbacks = [\n",
        "\tEpochCheckpoint(checkpoint, every=5, startAt=0),\n",
        "\tTrainingMonitor(figPath=myfigPath, jsonPath=myJsonPath, startAt=0)\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWL-mcLwAN5o",
        "outputId": "8cb04c93-0a6c-48e6-9db4-16a06ffef87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 63s 117ms/step - loss: 2.1594 - accuracy: 0.3683 - val_loss: 1.9507 - val_accuracy: 0.4665\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 1.7854 - accuracy: 0.5197 - val_loss: 1.6622 - val_accuracy: 0.5703\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 44s 113ms/step - loss: 1.5960 - accuracy: 0.5913 - val_loss: 1.5895 - val_accuracy: 0.5987\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 1.4486 - accuracy: 0.6453 - val_loss: 1.4842 - val_accuracy: 0.6444\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 1.3468 - accuracy: 0.6848 - val_loss: 1.3305 - val_accuracy: 0.6954\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 1.2521 - accuracy: 0.7172 - val_loss: 1.3266 - val_accuracy: 0.6938\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 1.1806 - accuracy: 0.7444 - val_loss: 1.2263 - val_accuracy: 0.7307\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 1.1195 - accuracy: 0.7652 - val_loss: 1.2368 - val_accuracy: 0.7310\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 1.0700 - accuracy: 0.7800 - val_loss: 1.1324 - val_accuracy: 0.7625\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 44s 112ms/step - loss: 1.0331 - accuracy: 0.7916 - val_loss: 1.2460 - val_accuracy: 0.7223\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.9938 - accuracy: 0.8067 - val_loss: 1.1592 - val_accuracy: 0.7606\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.9600 - accuracy: 0.8157 - val_loss: 1.1484 - val_accuracy: 0.7519\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.9279 - accuracy: 0.8252 - val_loss: 1.0323 - val_accuracy: 0.7910\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.9055 - accuracy: 0.8303 - val_loss: 1.0571 - val_accuracy: 0.7865\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 44s 113ms/step - loss: 0.8769 - accuracy: 0.8402 - val_loss: 1.0392 - val_accuracy: 0.7878\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.8577 - accuracy: 0.8440 - val_loss: 0.9652 - val_accuracy: 0.8140\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.8381 - accuracy: 0.8510 - val_loss: 1.0319 - val_accuracy: 0.7989\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.8171 - accuracy: 0.8573 - val_loss: 0.9749 - val_accuracy: 0.8150\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.7945 - accuracy: 0.8623 - val_loss: 1.0515 - val_accuracy: 0.7913\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 44s 114ms/step - loss: 0.7813 - accuracy: 0.8662 - val_loss: 0.8829 - val_accuracy: 0.8388\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.7604 - accuracy: 0.8733 - val_loss: 0.9513 - val_accuracy: 0.8127\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.7460 - accuracy: 0.8767 - val_loss: 0.9234 - val_accuracy: 0.8275\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.7339 - accuracy: 0.8785 - val_loss: 0.9096 - val_accuracy: 0.8344\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.7191 - accuracy: 0.8840 - val_loss: 0.8315 - val_accuracy: 0.8479\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 0.7068 - accuracy: 0.8859 - val_loss: 0.8906 - val_accuracy: 0.8354\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.6898 - accuracy: 0.8899 - val_loss: 0.9077 - val_accuracy: 0.8290\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.6800 - accuracy: 0.8927 - val_loss: 0.8775 - val_accuracy: 0.8412\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.6654 - accuracy: 0.8962 - val_loss: 0.8760 - val_accuracy: 0.8387\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.6562 - accuracy: 0.8987 - val_loss: 0.8420 - val_accuracy: 0.8484\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 44s 112ms/step - loss: 0.6445 - accuracy: 0.9022 - val_loss: 0.8757 - val_accuracy: 0.8365\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.6399 - accuracy: 0.9023 - val_loss: 0.8587 - val_accuracy: 0.8446\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.6197 - accuracy: 0.9091 - val_loss: 0.7970 - val_accuracy: 0.8547\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.6133 - accuracy: 0.9084 - val_loss: 0.9618 - val_accuracy: 0.8189\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.6066 - accuracy: 0.9098 - val_loss: 0.8392 - val_accuracy: 0.8439\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 44s 113ms/step - loss: 0.5957 - accuracy: 0.9128 - val_loss: 0.8753 - val_accuracy: 0.8376\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.5878 - accuracy: 0.9141 - val_loss: 0.7909 - val_accuracy: 0.8587\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.5798 - accuracy: 0.9169 - val_loss: 0.7872 - val_accuracy: 0.8586\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.5679 - accuracy: 0.9201 - val_loss: 0.8336 - val_accuracy: 0.8478\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.5659 - accuracy: 0.9193 - val_loss: 0.7696 - val_accuracy: 0.8608\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 44s 113ms/step - loss: 0.5546 - accuracy: 0.9232 - val_loss: 0.8452 - val_accuracy: 0.8401\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.5471 - accuracy: 0.9234 - val_loss: 0.7721 - val_accuracy: 0.8664\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.5397 - accuracy: 0.9266 - val_loss: 0.7602 - val_accuracy: 0.8599\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.5332 - accuracy: 0.9272 - val_loss: 0.8203 - val_accuracy: 0.8471\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.5321 - accuracy: 0.9248 - val_loss: 0.7625 - val_accuracy: 0.8647\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.5229 - accuracy: 0.9288 - val_loss: 0.7751 - val_accuracy: 0.8564\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.5146 - accuracy: 0.9313 - val_loss: 0.7414 - val_accuracy: 0.8671\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.5076 - accuracy: 0.9330 - val_loss: 0.7527 - val_accuracy: 0.8684\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.5028 - accuracy: 0.9343 - val_loss: 0.7411 - val_accuracy: 0.8692\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4949 - accuracy: 0.9361 - val_loss: 0.7765 - val_accuracy: 0.8563\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 44s 112ms/step - loss: 0.4913 - accuracy: 0.9361 - val_loss: 0.7322 - val_accuracy: 0.8711\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4867 - accuracy: 0.9358 - val_loss: 0.7574 - val_accuracy: 0.8641\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4802 - accuracy: 0.9378 - val_loss: 0.7881 - val_accuracy: 0.8533\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4754 - accuracy: 0.9398 - val_loss: 0.7283 - val_accuracy: 0.8734\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4666 - accuracy: 0.9414 - val_loss: 0.7817 - val_accuracy: 0.8500\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4644 - accuracy: 0.9422 - val_loss: 0.7819 - val_accuracy: 0.8556\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4579 - accuracy: 0.9433 - val_loss: 0.7974 - val_accuracy: 0.8509\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4566 - accuracy: 0.9430 - val_loss: 0.7509 - val_accuracy: 0.8590\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4506 - accuracy: 0.9437 - val_loss: 0.7806 - val_accuracy: 0.8552\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4461 - accuracy: 0.9449 - val_loss: 0.7713 - val_accuracy: 0.8553\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.4419 - accuracy: 0.9455 - val_loss: 0.7578 - val_accuracy: 0.8631\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4364 - accuracy: 0.9460 - val_loss: 0.7266 - val_accuracy: 0.8711\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4313 - accuracy: 0.9480 - val_loss: 0.8359 - val_accuracy: 0.8452\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4293 - accuracy: 0.9479 - val_loss: 0.7365 - val_accuracy: 0.8612\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4276 - accuracy: 0.9485 - val_loss: 0.7293 - val_accuracy: 0.8642\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.4229 - accuracy: 0.9487 - val_loss: 0.7392 - val_accuracy: 0.8639\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4204 - accuracy: 0.9490 - val_loss: 0.7761 - val_accuracy: 0.8547\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4121 - accuracy: 0.9508 - val_loss: 0.7179 - val_accuracy: 0.8653\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4111 - accuracy: 0.9507 - val_loss: 0.7344 - val_accuracy: 0.8662\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.4026 - accuracy: 0.9541 - val_loss: 0.7530 - val_accuracy: 0.8642\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.4044 - accuracy: 0.9508 - val_loss: 0.6320 - val_accuracy: 0.8844\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.4002 - accuracy: 0.9536 - val_loss: 0.7550 - val_accuracy: 0.8618\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3904 - accuracy: 0.9556 - val_loss: 0.7024 - val_accuracy: 0.8713\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3892 - accuracy: 0.9558 - val_loss: 0.7752 - val_accuracy: 0.8600\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3866 - accuracy: 0.9555 - val_loss: 0.6937 - val_accuracy: 0.8769\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.3885 - accuracy: 0.9545 - val_loss: 0.7415 - val_accuracy: 0.8652\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3874 - accuracy: 0.9551 - val_loss: 0.6617 - val_accuracy: 0.8798\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3834 - accuracy: 0.9565 - val_loss: 0.7859 - val_accuracy: 0.8475\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.3763 - accuracy: 0.9580 - val_loss: 0.6648 - val_accuracy: 0.8825\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3713 - accuracy: 0.9597 - val_loss: 0.6559 - val_accuracy: 0.8821\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.3710 - accuracy: 0.9583 - val_loss: 0.6786 - val_accuracy: 0.8726\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3666 - accuracy: 0.9589 - val_loss: 0.7327 - val_accuracy: 0.8649\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3700 - accuracy: 0.9577 - val_loss: 0.7043 - val_accuracy: 0.8684\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3648 - accuracy: 0.9587 - val_loss: 0.7549 - val_accuracy: 0.8640\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.3601 - accuracy: 0.9604 - val_loss: 0.8129 - val_accuracy: 0.8548\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.3580 - accuracy: 0.9603 - val_loss: 0.7229 - val_accuracy: 0.8612\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3515 - accuracy: 0.9626 - val_loss: 0.7253 - val_accuracy: 0.8660\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3564 - accuracy: 0.9610 - val_loss: 0.7329 - val_accuracy: 0.8611\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3521 - accuracy: 0.9619 - val_loss: 0.7224 - val_accuracy: 0.8708\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3474 - accuracy: 0.9622 - val_loss: 0.6691 - val_accuracy: 0.8770\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 0.3476 - accuracy: 0.9613 - val_loss: 0.7303 - val_accuracy: 0.8659\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3405 - accuracy: 0.9638 - val_loss: 0.8698 - val_accuracy: 0.8437\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.3454 - accuracy: 0.9612 - val_loss: 0.7015 - val_accuracy: 0.8715\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3383 - accuracy: 0.9630 - val_loss: 0.6871 - val_accuracy: 0.8755\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3403 - accuracy: 0.9635 - val_loss: 0.6620 - val_accuracy: 0.8795\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.3327 - accuracy: 0.9657 - val_loss: 0.6854 - val_accuracy: 0.8744\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3348 - accuracy: 0.9640 - val_loss: 0.5778 - val_accuracy: 0.9017\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3333 - accuracy: 0.9640 - val_loss: 0.7169 - val_accuracy: 0.8669\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3310 - accuracy: 0.9655 - val_loss: 0.6430 - val_accuracy: 0.8823\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 43s 109ms/step - loss: 0.3288 - accuracy: 0.9645 - val_loss: 0.6732 - val_accuracy: 0.8829\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 0.3258 - accuracy: 0.9656 - val_loss: 0.8329 - val_accuracy: 0.8444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b0a912e10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size=128),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // 128, \n",
        "\tepochs=100,\n",
        "\tcallbacks=callbacks,\n",
        "\tverbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS9ZYTIbcEnS"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mqvOuaicIlB",
        "outputId": "5275a7e3-622e-4867-c06c-71202e378f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NsmG6QOkcKry"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/My Drive/data_science/models/cifar-10-model_v3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru3rp9sSfJda"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9uYsPlzocwya"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "icEodA2th2OE"
      },
      "outputs": [],
      "source": [
        "import requests as r\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ifLXG7FMfjgQ"
      },
      "outputs": [],
      "source": [
        "trained_model = load_model(\"/content/drive/My Drive/data_science/models/cifar-10-model_v2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1YD-0Kfrf1re"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://media.wired.com/photos/5b806816be2f8d3a624b77c9/16:9/w_1072,h_603,c_limit/DIVO1.jpg\"\n",
        "response = r.get(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YAI_WmONf3zZ"
      },
      "outputs": [],
      "source": [
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.convert('RGB')\n",
        "img = img.resize((32,32))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0cOXOYoQmJdP"
      },
      "outputs": [],
      "source": [
        "img_array = img_to_array(img)\n",
        "img_array = img_array[None, ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBEQs7YNjTnT",
        "outputId": "bc4da647-1005-464f-e950-6d0fd51b393b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.26937419e-04, 9.58119154e-01, 6.07863403e-05, 3.99416749e-04,\n",
              "        1.61721371e-04, 1.00733516e-04, 3.19058783e-02, 9.03706405e-06,\n",
              "        9.07602254e-03, 4.04356651e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "trained_model.predict(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_orwdZsFj1Qy"
      },
      "outputs": [],
      "source": [
        "gtLabels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j31T_Emmay3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cifar10-image-classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}